{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFGqKSh0CgOf"
      },
      "source": [
        "# Automatic form filling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gx2hAojCgOj"
      },
      "source": [
        "Required packages:\n",
        "- pip install pypdf2\n",
        "- pip install pymupdf\n",
        "- pip install openai\n",
        "- pip install pandas\n",
        "- pip install openpyxl\n",
        "- pip install numpy\n",
        "- pip install opencv-python\n",
        "- pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev6SifJNCgOj"
      },
      "source": [
        "Replace api_key and selected_model from the config.py to your custom LLM api key and selected_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "-Qg52UmtCgOk",
        "outputId": "a0311aa2-4ad4-4427-ecfa-20a9e5fda999"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-eb022e26cf56>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput_pdf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/BCU-application-form.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from config import api_key, selected_model\n",
        "\n",
        "output_pdf_path = \"/content/BCU-application-form.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgotwHjfFun2",
        "outputId": "6a404013-8e1b-4774-c5bb-b6ea695d8d2c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKUNDLkHFx-5",
        "outputId": "7c7c18e9-58c8-4df6-db5a-d4a62a187642"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading PyMuPDF-1.24.0-cp310-none-manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.0 (from pymupdf)\n",
            "  Downloading PyMuPDFb-1.24.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/30.8 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
            "Successfully installed PyMuPDFb-1.24.0 pymupdf-1.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z4ZVRAnF2pZ",
        "outputId": "0c6adad1-dbf8-4305-f806-8dbf66371fa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVvSt6z2F4bF",
        "outputId": "f1ac3edc-2820-410a-8b92-8ca0697d89a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2zhjCPRF4X9",
        "outputId": "a0d3d7a5-78c1-48d3-e33b-e7439aca0716"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeocNs0HF4Vg",
        "outputId": "b5d17da4-bed4-4416-e890-e1d607955108"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlgfvYq5F7E9",
        "outputId": "7f3806fd-eb64-49ad-a080-0246f6915a51"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKQzS3j1F9FL",
        "outputId": "4c7d82d1-d82d-48a6-ec16-eb6727534b92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70X86KxYIJuF",
        "outputId": "c8b3c0af-0a53-48b2-be65-2b1e7ad6af39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.10.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HlYNzdHTCgOl"
      },
      "outputs": [],
      "source": [
        "# Packages\n",
        "import requests\n",
        "import openai\n",
        "import fitz  # Import the PyMuPDF library\n",
        "import pandas as pd\n",
        "import os\n",
        "import openpyxl\n",
        "import numpy as np\n",
        "import io\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from math import sqrt\n",
        "from docx import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XcaX2k-rCgOl"
      },
      "outputs": [],
      "source": [
        "# Explain why extra questions are needed\n",
        "extra_questions = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azblmah2CgOm"
      },
      "outputs": [],
      "source": [
        "~# Explain why load the data ? What is the use, maybe include a screenshot of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQg7228yCgOm"
      },
      "source": [
        "### 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kHV1LNFkCgOm"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "    # Determine the file extension\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    # Load the file based on its extension\n",
        "    if file_extension in ['.xls', '.xlsx']:\n",
        "        # It's an Excel file\n",
        "        df = pd.read_excel(file_path)\n",
        "    elif file_extension in ['.csv', '.txt']:\n",
        "        # It's a CSV or a text file\n",
        "        df = pd.read_csv(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "    # Convert the DataFrame to a dictionary (assuming you want to use all data as context)\n",
        "    data_context_dict = df.to_dict(orient='records')[0]  # Taking the first row as an example\n",
        "\n",
        "    return data_context_dict\n",
        "\n",
        "# Example usage\n",
        "file_path = '/content/students.xlsx'\n",
        "data_context_dict = load_data(file_path)\n",
        "# Convert the dictionary to a string context\n",
        "data_context = '. '.join([f\"{key} is {value}\" for key, value in data_context_dict.items()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4FZR6mtCgOm"
      },
      "source": [
        "### 2. General Functions for Form Filling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SmM3vO1GCgOm"
      },
      "outputs": [],
      "source": [
        "def call_chat_gpt(prompt, api_key, selected_model):\n",
        "    url = \"https://api.openai.com/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": selected_model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "    response = requests.post(url, json=payload, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "def answer_cleanup(output):\n",
        "    try:\n",
        "        return output['choices'][0]['message']['content']\n",
        "    except (KeyError, IndexError, TypeError):\n",
        "        return \"Error in processing the response.\"\n",
        "\n",
        "\n",
        "def identify_keywords_with_llm(pdf_text, api_key, selected_model):\n",
        "    # Craft a prompt asking the LLM to identify the keywords\n",
        "    prompt = f\"\"\"\n",
        "Given the text, identify and list only the explicit questions and statements that indicate a requirement for user input. This includes:\n",
        "\n",
        "- Direct questions that clearly ask for specific information (e.g., \"What is your name?\").\n",
        "- Statements or phrases that directly imply a requirement for a response or filling a blank (e.g., \"Name of the applicant: _______\").\n",
        "- Explicit prompts for specific types of information, irrespective of whether they are formatted as questions or statements (e.g., \"Date of birth:\", \"Briefly describe your experience with...\").\n",
        "\n",
        "Exclude:\n",
        "- General descriptive text or narrative explanations.\n",
        "- Any content that does not directly request user input or response.\n",
        "- Colons (\":\") at the end of questions or statements.\n",
        "\n",
        "Important formatting requirements that should be implemented for the output:\n",
        "- Remove any leading characters such as dashes ('-'), colons (\":\"), list numbers, or all punctuation from the beginning of each line to focus solely on the content.\n",
        "- Retain the original text format as much as possible beyond the initial character removal to ensure clarity and ease of reading.\n",
        "- Extract the clean text of each question or statement requesting user input, excluding any extraneous elements, formatting characters, or colons at the end.\n",
        "- Include all variations of input requests, whether they are formatted as direct questions, implied statements, or instructional texts, without the initial formatting characters and colons at the end.\n",
        "\n",
        "Please process the text with these instructions:\n",
        "\n",
        "{pdf_text}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    # Assuming you have a function `call_chat_gpt` similar to previous examples\n",
        "    llm_response = call_chat_gpt(prompt, api_key, selected_model)\n",
        "    response = answer_cleanup(llm_response)\n",
        "    keywords_from_llm_1 = response.split('\\n')\n",
        "    keywords_from_llm = [keyword.lstrip('- ').strip() for keyword in keywords_from_llm_1]\n",
        "    return keywords_from_llm\n",
        "\n",
        "\n",
        "# Explain Next Step\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ESlXNPTCgOn"
      },
      "source": [
        "### 3. Functions for PDF Filling Processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tz0r5PEPCgOn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_all_text(pdf_path):\n",
        "    # Open the PDF file\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    all_text = \"\"  # Initialize a variable to store all the extracted text\n",
        "\n",
        "    # Iterate through each page in the PDF\n",
        "    for page in doc:\n",
        "        # Extract text from the current page\n",
        "        page_text = page.get_text()\n",
        "        all_text += page_text + \"\\n\"  # Append the text from this page, add a newline as separator\n",
        "\n",
        "    return all_text\n",
        "def generate_answer_with_context(context, question, api_key, selected_model):\n",
        "    # Update the prompt to specify that the response should be \"Insufficient data\" if not enough context is provided\n",
        "    prompt = prompt = f\"Based on the following details: {context}, if the information is explicitly provided, what is the concise answer (preferably a single word or a short phrase) for '{question}'? Keep the response brief. If not enough information is available for a question, just respond with ''.\"\n",
        "# Use this 'prompt' with your LLM to generate the response.\n",
        "\n",
        "    response = call_chat_gpt(prompt, api_key, selected_model)\n",
        "    cleaned_response = answer_cleanup(response).strip()\n",
        "\n",
        "    # Check if the response is \"Insufficient data\" or similar to indicate not to generate an answer\n",
        "    if cleaned_response.lower() == \"\":\n",
        "        return None  # Or any suitable indicator for no answer due to insufficient context\n",
        "    else:\n",
        "        return cleaned_response\n",
        "\n",
        "\n",
        "# Explain the function\n",
        "def extract_images_from_pdf(pdf_path):\n",
        "    images = []\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page in doc:\n",
        "        pix = page.get_pixmap()\n",
        "        img_bytes = pix.tobytes(output=\"png\")\n",
        "        image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "        # Convert RGB to BGR for OpenCV\n",
        "        image_np = image_np[:, :, ::-1].copy()\n",
        "        images.append(image_np)\n",
        "    return images\n",
        "\n",
        "\n",
        "def find_boxes_in_image(image):\n",
        "    boxes = []\n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "        edges = cv2.Canny(blur, 100, 200)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        for contour in contours:\n",
        "            approx = cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)\n",
        "            if len(approx) == 4:\n",
        "                # approx contains the coordinates of the 4 corners\n",
        "                corners = approx.reshape(-1, 2)  # Reshape to Nx2 where N=number of corners (should be 4)\n",
        "                boxes.append(corners.tolist())  # Convert numpy array to list and append to boxes\n",
        "    except cv2.error as e:\n",
        "        print(f\"Error in finding boxes: {e}\")\n",
        "    return boxes  # Return the list of boxes directly\n",
        "\n",
        "\n",
        "def calculate_rectangle_area(box):\n",
        "    xs = [point[0] for point in box]\n",
        "    ys = [point[1] for point in box]\n",
        "    width = max(xs) - min(xs)\n",
        "    height = max(ys) - min(ys)\n",
        "    return width * height\n",
        "\n",
        "\n",
        "def extract_text_coordinates(pdf_path, keywords):\n",
        "    \"\"\"\n",
        "    Extract text and their coordinates from a PDF for specific keywords.\n",
        "\n",
        "    :param pdf_path: Path to the PDF file.\n",
        "    :param keywords: A list of keywords to search for in the PDF.\n",
        "    :return: A list of dictionaries containing page numbers, text, and their coordinates for all four corners.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)  # Open the PDF\n",
        "    text_info = []  # List to hold text and coordinates\n",
        "\n",
        "    for page_num in range(len(doc)):  # Iterate through each page\n",
        "        page = doc.load_page(page_num)  # Load the current page\n",
        "        text_instances = page.get_text(\"dict\")[\"blocks\"]  # Extract text instances as dictionaries\n",
        "\n",
        "        for instance in text_instances:\n",
        "            if 'lines' in instance:  # Check if the block contains lines of text\n",
        "                for line in instance['lines']:\n",
        "                    for span in line['spans']:  # Iterate through each text span in the line\n",
        "                        text = span['text']\n",
        "                        if any(keyword.lower() in text.lower() for keyword in keywords):\n",
        "                            bbox = span['bbox']  # Bounding box of the text\n",
        "\n",
        "                            # Calculate all four corners based on bbox\n",
        "                            corners = [\n",
        "                                (bbox[0], bbox[1]),  # Bottom-left\n",
        "                                (bbox[2], bbox[1]),  # Bottom-right\n",
        "                                (bbox[2], bbox[3]),  # Top-right\n",
        "                                (bbox[0], bbox[3])   # Top-left\n",
        "                            ]\n",
        "                            text_info.append({\n",
        "                                \"page\": page_num,\n",
        "                                \"text\": text,\n",
        "                                \"corners\": corners  # List of all four corner coordinates\n",
        "                            })\n",
        "\n",
        "    return text_info\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_euclidean_distance(point1, point2):\n",
        "    \"\"\"\n",
        "    Calculate the Euclidean distance between two points.\n",
        "    \"\"\"\n",
        "    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
        "\n",
        "\n",
        "def find_closest_box(text_coordinates, box_coordinates):\n",
        "    closest_boxes = []  # Initialize the list to store results\n",
        "\n",
        "    for text_item in text_coordinates:\n",
        "        question_page = text_item['page']  # Get the page number of the text item\n",
        "        # Assuming the corners are ordered as bottom-left, bottom-right, top-right, top-left\n",
        "        text_top_right = text_item['corners'][2]  # Top right corner of the text\n",
        "\n",
        "        min_distance = float('inf')  # Initialize minimum distance to infinity\n",
        "        closest_box = None  # Initialize closest box to None\n",
        "\n",
        "        # Ensure we're looking at the correct page's boxes\n",
        "        if question_page < len(box_coordinates):\n",
        "            for box in box_coordinates[question_page]:\n",
        "                # Correctly access the top left corner of the box directly\n",
        "                # Assuming corners order: bottom-left, bottom-right, top-right, top-left\n",
        "                box_top_left = box[3]  # Direct access to the top left corner\n",
        "\n",
        "                # Calculate Euclidean distance from text top right to box top left\n",
        "                distance = calculate_euclidean_distance(text_top_right, box_top_left)\n",
        "\n",
        "                # Update the closest box if the current box is closer\n",
        "                if distance < min_distance:\n",
        "                    min_distance = distance\n",
        "                    closest_box = box  # Store the entire box as the closest box\n",
        "\n",
        "        # Append the result for the current question to the list\n",
        "        closest_boxes.append({\n",
        "            'question': text_item['text'],\n",
        "            'closest_box': closest_box,\n",
        "            'page': question_page\n",
        "        })\n",
        "\n",
        "    return closest_boxes\n",
        "\n",
        "\n",
        "def save_generated_pdf(input_pdf_path, question_answer_boxes, answers, output_pdf_path, closest_boxes):\n",
        "    doc = fitz.open(input_pdf_path)\n",
        "\n",
        "    for item in closest_boxes:\n",
        "        question = item['question'].strip(':')  # Remove colon for matching\n",
        "        closest_box = item['closest_box']\n",
        "        page_number = item['page']\n",
        "        answer = answers.get(question, '')  # Get the answer for the question\n",
        "\n",
        "        if answer:\n",
        "            # Assuming closest_box is a list of points [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
        "            # and we'll use the top-left corner to position the text\n",
        "            # Sorting by x to get left points, then by y to get the topmost point\n",
        "            top_left_corner = sorted(closest_box, key=lambda point: (point[0], point[1]))[0]\n",
        "            # Adjusting the position slightly to the right (x + 2) and down (y + 10) for better visibility\n",
        "            position = (top_left_corner[0] + 2, top_left_corner[1] + 10)\n",
        "\n",
        "            page = doc.load_page(page_number)\n",
        "            # Insert the text at the adjusted position\n",
        "            page.insert_text(position, answer, fontsize=10)\n",
        "\n",
        "    doc.save(output_pdf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st8qW1WdCgOo"
      },
      "source": [
        "### 4. Implementing the functions to fill the PDF form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n-J4vdVTCgOo"
      },
      "outputs": [],
      "source": [
        "api_key = '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'\n",
        "selected_model = 'gpt-3.5-turbo'\n",
        "# Specify the path to your PDF file\n",
        "pdf_path = '/content/BCU-application-form.pdf'\n",
        "\n",
        "# Extract all text\n",
        "extracted_text = extract_all_text(pdf_path)\n",
        "\n",
        "\n",
        "# Call the LLM with the extracted PDF text\n",
        "keywords_from_llm = identify_keywords_with_llm(extracted_text, api_key, selected_model)\n",
        "\n",
        "# include extra questions\n",
        "if extra_questions:\n",
        "    keywords_from_llm.extend(extra_questions)\n",
        "\n",
        "# Generate answers for each keyword\n",
        "answers = {keyword: generate_answer_with_context(data_context_dict, keyword, api_key, selected_model) for keyword in keywords_from_llm}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaurlM5eL_Qn",
        "outputId": "cbeec734-4539-4cb4-d25f-1d2196712548"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Course Title': 'Principles of Machine Learning',\n",
              " 'Proposed start date': \"''\",\n",
              " 'Full-time': \"''\",\n",
              " 'Part-time': \"''\",\n",
              " 'Proposed Year/Level of Entry': '2',\n",
              " 'Year 1': \"''\",\n",
              " 'Year 2': 'Second Year',\n",
              " 'Year 3': \"''.\",\n",
              " 'Title': \"''\\n\\nThere is no information provided for the 'Title' field.\",\n",
              " 'Gender': 'Female',\n",
              " 'Date of birth': '1967-11-07',\n",
              " 'First name(s)': 'John',\n",
              " 'Maiden or any other name(s) that you have been known by': \"''\",\n",
              " 'Surname/family name': 'Jackson',\n",
              " 'Permanent address': '133 Magnolia Path, Springfield, MI 78901',\n",
              " 'Country': 'USA',\n",
              " 'Postcode': '78901',\n",
              " 'Correspondence address (if different)': \"''\",\n",
              " 'Daytime telephone': '(931) 726-2700',\n",
              " 'Evening telephone (if different)': \"''\",\n",
              " 'Mobile': '(931) 726-2700',\n",
              " 'Email address': 'user701@yahoo.com',\n",
              " 'Nationality': \"''\",\n",
              " 'If not born in the UK please state date of arrival to UK': \"''\",\n",
              " 'Area of permanent residence': 'Springfield',\n",
              " 'If you are a member of a Professional Body, please give its name and your Registration Number': 'N/A',\n",
              " 'Have you ever studied in the UK before?': 'No.',\n",
              " 'What level was your previous study in the UK (please tick all that apply)?': 'Level 2',\n",
              " 'Have you ever studied at Birmingham City University before?': 'No',\n",
              " 'Day': 'Wednesday',\n",
              " 'Month': 'November',\n",
              " 'Year': '1967',\n",
              " 'Please enter details of the highest level of qualification you currently hold': 'Level 2',\n",
              " 'Now please list all other qualifications taken, whatever the result, in reverse chronological order ie: latest first': \"''\",\n",
              " 'If you have a 10 digit Unique Learner Number (ULN), please enter it in the box provided': \"''\",\n",
              " 'If you are an overseas student please include your IELTS/TOEFL results below': \"''\",\n",
              " 'IELTS overall band score': \"''\",\n",
              " 'TOEFL internet-based test score': \"''\",\n",
              " 'Please give details of work experience, training and employment in reverse chronological order': \"''\",\n",
              " 'Name': 'John Jackson',\n",
              " 'Address': '133 Magnolia Path, Springfield, MI 78901',\n",
              " 'Telephone': '(931) 726-2700',\n",
              " 'Fax': \"''\",\n",
              " 'Email': 'user701@yahoo.com',\n",
              " 'Please enter here any further information in support of your application, for example, reasons for choosing the course, your professional career to date (if relevant) and your current career goals': 'Not provided',\n",
              " 'Did you use an agent to help you find this course?': \"''\",\n",
              " 'Agent’s name': \"''\",\n",
              " 'Agent’s email': 'user701@yahoo.com',\n",
              " 'Please list these above or on a separate sheet if necessary': 'List above',\n",
              " 'I confirm that the information given on this form is true, complete and accurate and that none of the information requested or other material information has been omitted': 'True',\n",
              " 'Birmingham City University reserves the right to cancel my application, withdraw its offer of a place or terminate attendance at the University and I shall have no claim against Birmingham City University in relation thereto': 'Acceptance',\n",
              " 'Applicant’s name': 'John Jackson',\n",
              " 'Applicant’s signature': \"''.\",\n",
              " 'Date': '1967-11-07',\n",
              " 'PLEASE INDICATE HOW YOU HEARD ABOUT THE COURSE (please tick relevant boxes)': \"''\",\n",
              " 'Do you have any special needs? (please tick)': \"''\",\n",
              " 'A': 'Female',\n",
              " 'No disability': 'No disability',\n",
              " 'B': 'Female',\n",
              " 'You have a social/communication impairment such as Asperger’s syndrome/other autistic spectrum disorder': \"''\",\n",
              " 'C': \"''.\",\n",
              " 'You are blind or have a serious visual impairment uncorrected by glasses': \"''\",\n",
              " 'D': \"Timestamp('').\",\n",
              " 'You are deaf or have a serious hearing impairment': \"''\",\n",
              " 'E': 'Female',\n",
              " 'You have a long standing illness or health condition such as cancer, HIV, diabetes, chronic heart disease, or epilepsy': \"''\",\n",
              " 'F': 'Female',\n",
              " 'You have a mental health condition, such as depression, schizophrenia or anxiety disorder': 'Depression',\n",
              " 'G': 'Female',\n",
              " 'You have a specific learning difficulty such as dyslexia, dyspraxia or AD(H)D': \"''.\",\n",
              " 'H': 'Female',\n",
              " 'You have a physical impairment or mobility issues, such as difficulty using your arms or using a wheelchair or crutches': 'No.',\n",
              " 'I': 'Female',\n",
              " 'You have a disability, impairment or medical condition that is not listed above': 'No.',\n",
              " 'J': 'Female',\n",
              " 'You have two or more impairments and/or disabling medical conditions': \"''\",\n",
              " 'Course applied for': 'Principles of Machine Learning',\n",
              " 'To the Referee': \"'Email'\",\n",
              " 'How long have you known the applicant and in what capacity': 'Not provided',\n",
              " 'Please comment on the applicant’s suitability for the course with particular reference to his/her strengths': 'Not enough information.',\n",
              " 'Please add any other comments you feel would be helpful in supporting their application to the University': 'No additional comments',\n",
              " 'Name of referee': \"''.\",\n",
              " 'Signature of referee': \"''\"}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN_UqKUoCgOo"
      },
      "source": [
        "#### 4.1 Using Image Analysis in box detection and filling the form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X2Yiw9HUCgOo"
      },
      "outputs": [],
      "source": [
        "output_pdf_path='/content/Doc1.pdf'\n",
        "# Extract images from PDF\n",
        "images = extract_images_from_pdf(pdf_path)\n",
        "\n",
        "# Initialize an empty list to hold the box coordinates for all images\n",
        "box_coordinates = []\n",
        "\n",
        "# Find answer box coordinates for each image and add them to the box_coordinates list\n",
        "for i, image in enumerate(images):\n",
        "    boxes = find_boxes_in_image(image)\n",
        "    box_coordinates.append(boxes)   # Add the boxes for this image to the main list\n",
        "\n",
        "filtered_box_coordinates = []\n",
        "\n",
        "for page_boxes in box_coordinates:\n",
        "    # Filter boxes based on their calculated area\n",
        "    filtered_boxes = [box for box in page_boxes if calculate_rectangle_area(box) >= 50]\n",
        "    filtered_box_coordinates.append(filtered_boxes)\n",
        "\n",
        "\n",
        "text_coordinates = extract_text_coordinates(pdf_path,keywords_from_llm)\n",
        "\n",
        "closest_boxes = find_closest_box(text_coordinates, filtered_box_coordinates)\n",
        "\n",
        "save_generated_pdf(pdf_path, closest_boxes, answers, output_pdf_path, closest_boxes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdCMyfz9CgOo"
      },
      "source": [
        "### 5. Marking the detected box coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1knnTj_CgOp"
      },
      "outputs": [],
      "source": [
        "def mark_boxes_in_pdf(pdf_path, box_coordinates, output_pdf_path):\n",
        "    \"\"\"\n",
        "    Marks the detected boxes in the PDF.\n",
        "\n",
        "    :param pdf_path: Path to the source PDF file.\n",
        "    :param box_coordinates: A nested list of box coordinates for each page, with each box defined by points.\n",
        "    :param output_pdf_path: Path to save the PDF with marked boxes.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    for page_number, page_boxes in enumerate(box_coordinates):\n",
        "        page = doc[page_number]  # Access the page\n",
        "        for box in page_boxes:  # box is a list of points for a single box\n",
        "            points = [fitz.Point(pt[0], pt[1]) for pt in box]  # Directly create fitz.Point objects for each point in the box\n",
        "\n",
        "            # Create an annotation (polygon) for the box\n",
        "            annot = page.add_polygon_annot(points)\n",
        "            annot.set_colors(stroke=(1, 0, 0))  # Set the polygon color to red\n",
        "            annot.set_border(width=1.5)  # Set the border width\n",
        "            annot.update()  # Apply the changes to the annotation\n",
        "\n",
        "    doc.save(output_pdf_path, garbage=4, deflate=True)  # Save the modified PDF\n",
        "\n",
        "mark_boxes_in_pdf(pdf_path, filtered_box_coordinates, output_pdf_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pNsBk1GCgOp"
      },
      "source": [
        "### 6. Functions for Word Filling Processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OYHLjg-jCgOp"
      },
      "outputs": [],
      "source": [
        "def convert_doc_to_docx(doc_path):\n",
        "    # Ensure the path is absolute\n",
        "    doc_path = os.path.abspath(doc_path)\n",
        "    # Create a .docx path for the converted file\n",
        "    docx_path = os.path.splitext(doc_path)[0] + \".docx\"\n",
        "\n",
        "    # Start Word application\n",
        "    word = win32.gencache.EnsureDispatch('Word.Application')\n",
        "    doc = word.Documents.Open(doc_path)\n",
        "    # Save the document in .docx format\n",
        "    doc.SaveAs2(docx_path, FileFormat=16)  # 16 represents wdFormatXMLDocument\n",
        "    doc.Close()\n",
        "    word.Quit()\n",
        "\n",
        "    return docx_path\n",
        "\n",
        "def extract_text_in_order(file_path):\n",
        "    # Check if file is .doc, convert to .docx\n",
        "    if file_path.endswith('.doc'):\n",
        "        print(\"Converting .doc to .docx\")\n",
        "        file_path = convert_doc_to_docx(file_path)\n",
        "\n",
        "    doc = Document(file_path)\n",
        "    extracted_text = []\n",
        "\n",
        "    # Extract text from paragraphs\n",
        "    for para in doc.paragraphs:\n",
        "        extracted_text.append(para.text)\n",
        "\n",
        "    # Extract text from tables\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            for cell in row.cells:\n",
        "                extracted_text.append(cell.text)\n",
        "\n",
        "    return extracted_text\n",
        "def generate_answer_with_context(context, question, api_key, selected_model):\n",
        "    # Update the prompt to specify that the response should be \"Insufficient data\" if not enough context is provided\n",
        "    prompt = (f\"Based on the following details: {context}, for the question '{question}', \"\n",
        "                  \"what is the concise answer (preferably a single word or a short phrase)? \"\n",
        "                  \"If not enough information is available, respond with 'Insufficient data'. \"\n",
        "                  \"For imaginative or creative questions, where crafting a story or providing an imaginative answer is suitable,and do not condider the condition ogf making the answer concise while you create a story for a question \"\n",
        "                  \"use the available context to craft a compelling, creative response that aligns with the theme or nature of the question.\")\n",
        "# Use this 'prompt' with your LLM to generate the response.\n",
        "\n",
        "    response = call_chat_gpt(prompt, api_key, selected_model)\n",
        "    cleaned_response = answer_cleanup(response).strip()\n",
        "\n",
        "    # Check if the response is \"Insufficient data\" or similar to indicate not to generate an answer\n",
        "    if cleaned_response.lower() == \"\":\n",
        "        return None  # Or any suitable indicator for no answer due to insufficient context\n",
        "    else:\n",
        "        return cleaned_response\n",
        "# Assuming convert_doc_to_docx function is defined elsewhere in your code\n",
        "\n",
        "def fill_in_answers(doc_path, answers_dict, output_file_name):\n",
        "    # Check if the file is a .doc file, and convert it to .docx if so\n",
        "    if doc_path.endswith(\".doc\"):\n",
        "        print(\"Converting .doc to .docx\")\n",
        "        doc_path = convert_doc_to_docx(doc_path)\n",
        "\n",
        "    doc = Document(doc_path)\n",
        "\n",
        "    # Process paragraphs in the document body\n",
        "    for i, para in enumerate(doc.paragraphs):\n",
        "        for keyword, answer in answers_dict.items():\n",
        "            if keyword.lower() in para.text.lower():  # Case insensitive search for the keyword\n",
        "                # Check if the next paragraph is empty and we are not at the last paragraph\n",
        "                if i + 1 < len(doc.paragraphs) and not doc.paragraphs[i + 1].text.strip():\n",
        "                    # Insert the answer into the next paragraph\n",
        "                    doc.paragraphs[i + 1].text = answer\n",
        "\n",
        "    # Process each table in the document\n",
        "    for table in doc.tables:\n",
        "        for row in table.rows:\n",
        "            for i, cell in enumerate(row.cells):\n",
        "                for keyword, answer in answers_dict.items():\n",
        "                    if keyword.lower() in cell.text.lower():\n",
        "                        # Attempt to find the next empty cell in the row\n",
        "                        if i + 1 < len(row.cells) and not row.cells[i + 1].text.strip():\n",
        "                            row.cells[i + 1].text = answer\n",
        "\n",
        "    # Construct the output path with .docx extension\n",
        "    output_dir = os.path.dirname(doc_path)  # Use the same directory as the input file\n",
        "    output_path = os.path.join(output_dir, output_file_name + \".docx\")\n",
        "\n",
        "    # Save the document to the specified output path\n",
        "    doc.save(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3kpF2nHCgOp"
      },
      "source": [
        "### 7. Implementing the functions to fill the word form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FZys-nL6CgOp"
      },
      "outputs": [],
      "source": [
        "# Specify the path to your PDF file\n",
        "word_path = '/content/PGT_Readmission_form_Dec_2020 .docx'\n",
        "\n",
        "# Extract all text\n",
        "extracted_text = extract_text_in_order(word_path)\n",
        "\n",
        "\n",
        "# Call the LLM with the extracted PDF text\n",
        "keywords_from_llm = identify_keywords_with_llm(extracted_text, api_key, selected_model)\n",
        "\n",
        "# include extra questions\n",
        "if extra_questions:\n",
        "    keywords_from_llm.extend(extra_questions)\n",
        "\n",
        "# Generate answers for each keyword\n",
        "answers = {keyword: generate_answer_with_context(data_context_dict, keyword, api_key, selected_model) for keyword in keywords_from_llm}\n",
        "output_path = 'fully filled'\n",
        "fill_in_answers(word_path,answers,output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeMQyz6LCgOq"
      },
      "source": [
        "### 8. Functions for Excel filling processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN_iyJLQCgOq"
      },
      "outputs": [],
      "source": [
        "def generate_answer_with_context(context, question, api_key, selected_model):\n",
        "    # Update the prompt to specify that the response should be \"Insufficient data\" if not enough context is provided\n",
        "    prompt = f\"Based on the following details: {context}, answer the question '{question}' as follows: If the question is a direct query seeking specific information (e.g., 'What is the capital of France?'), provide a concise answer (preferably a single word or a short phrase). If the question is analytical and seeks a deeper explanation (e.g., 'How does photosynthesis work?'), provide a detailed and analytical answer. For yes/no questions (e.g., 'Is the sky blue?'), respond with 'Yes' or 'No' and include a brief justification. If not enough information is available to accurately answer the question, respond with 'Insufficient information.'and only provide answers for a question once and in the output I just need the answers to be alone not with the questions\"\n",
        "\n",
        "# Use this 'prompt' with your LLM to generate the response.\n",
        "\n",
        "    response = call_chat_gpt(prompt, api_key, selected_model)\n",
        "    cleaned_response = answer_cleanup(response).strip()\n",
        "\n",
        "    # Check if the response is \"Insufficient data\" or similar to indicate not to generate an answer\n",
        "    if cleaned_response.lower() == \"\":\n",
        "        return None  # Or any suitable indicator for no answer due to insufficient context\n",
        "    else:\n",
        "        return cleaned_response\n",
        "    # Function to convert CSV to XLSX if necessary and return the path to the XLSX file\n",
        "def ensure_xlsx(file_path):\n",
        "    dir_name, file_name = os.path.split(file_path)\n",
        "    base_name, extension = os.path.splitext(file_name)\n",
        "\n",
        "    # If the file is a CSV, convert it to XLSX\n",
        "    if extension.lower() == '.csv':\n",
        "        df = pd.read_csv(file_path)\n",
        "        new_file_path = os.path.join(dir_name, base_name + '.xlsx')\n",
        "        df.to_excel(new_file_path, index=False)  # Save the DataFrame as an XLSX file\n",
        "        return new_file_path\n",
        "    elif extension.lower() in ['.xls', '.xlsx']:\n",
        "        return file_path\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbBJB5CGCgOq"
      },
      "source": [
        "### 9. Implementing the functions to fill the Excel form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeDsX87tCgOq"
      },
      "outputs": [],
      "source": [
        "excel_path = 'C:/Users/rosha/OneDrive/Desktop/projects/Dissertation/forms/authorised_interruption_of_study_application_1.docx'\n",
        "data = pd.read_excel(excel_path)\n",
        "data_string = '\\n'.join(data.applymap(str).stack().tolist())\n",
        "\n",
        "keywords_from_llm = identify_keywords_with_llm(extracted_text, api_key, selected_model)\n",
        "\n",
        "# include extra questions\n",
        "if extra_questions:\n",
        "    keywords_from_llm.extend(extra_questions)\n",
        "\n",
        "# Generate answers for each keyword\n",
        "answers = {keyword: generate_answer_with_context(data_context_dict, keyword, api_key, selected_model) for keyword in keywords_from_llm}\n",
        "# Ensure the file is in XLSX format\n",
        "xlsx_file_path = ensure_xlsx(excel_path)\n",
        "\n",
        "wb = openpyxl.load_workbook(xlsx_file_path)\n",
        "sheet = wb.active\n",
        "\n",
        "# Iterate over the rows and columns to find the questions\n",
        "for row in range(1, sheet.max_row + 1):\n",
        "    for col in range(1, sheet.max_column + 1):\n",
        "        cell = sheet.cell(row=row, column=col)\n",
        "        cell_value = cell.value\n",
        "        if cell_value in answers:\n",
        "            # Once the question is found, search for the next empty cell in the same row\n",
        "            for answer_col in range(col + 1, sheet.max_column + 2):\n",
        "                next_cell = sheet.cell(row=row, column=answer_col)\n",
        "                if next_cell.value is None or isinstance(next_cell, openpyxl.cell.cell.MergedCell):\n",
        "                    # Find the top-left cell of the merged range that includes the next_cell\n",
        "                    for range_ in sheet.merged_cells.ranges:\n",
        "                        if next_cell.coordinate in range_:\n",
        "                            top_left_cell = sheet.cell(range_.min_row, range_.min_col)\n",
        "                            top_left_cell.value = answers[cell_value]\n",
        "                            break\n",
        "                    else:\n",
        "                        # If next_cell is not a merged cell, just assign the value directly\n",
        "                        next_cell.value = answers[cell_value]\n",
        "                    break  # Exit the loop after inserting the answer\n",
        "\n",
        "# Define a new file name by appending \"filled\" before the file extension in the original file path\n",
        "dir_name, file_name = os.path.split(excel_path)\n",
        "base_name, extension = os.path.splitext(file_name)\n",
        "new_file_name = base_name + \"_filled\" + extension\n",
        "new_file_path = os.path.join(dir_name, new_file_name)\n",
        "\n",
        "# Save the updated workbook to the new file path\n",
        "wb.save(new_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK_PjcSzCgOr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}